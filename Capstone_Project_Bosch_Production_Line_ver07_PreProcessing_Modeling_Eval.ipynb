{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9d06f0-cf73-4648-bcfa-d89475607b9a",
   "metadata": {},
   "source": [
    "# Data checks\n",
    "- Create a subset of the training data (randomized 100,000 rows for training data set while keeping the index is same for the numerical, categorical and date data)\n",
    "- Create a subset of the test data (randomized 30,000 rows for the test data set while keeping the index same for the numerical, categorical and date data)\n",
    "- Missing values\n",
    "- Identify duplicates\n",
    "- Identify outliers\n",
    "- Box plot, IQR, Z score\n",
    "- Data types that are correct\n",
    "- Incorrect or impossible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bd9d6-25d3-4928-9158-9a000f902188",
   "metadata": {},
   "source": [
    "# Prepare the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e443ab-fbbe-4478-a510-cd335cb8f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_rows = 1184687  # Total rows including header\n",
    "sample_size = 100000\n",
    "\n",
    "# Generate a shared random sample of row indices to KEEP (excluding the header row)\n",
    "rows_to_keep = sorted(np.random.choice(np.arange(1, total_rows), size=sample_size, replace=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0879980f-9af3-488d-9776-7b4186d5efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data rows (excluding header) are 1 to total_rows-1\n",
    "all_rows = set(range(1, total_rows))\n",
    "rows_to_skip = sorted(all_rows - set(rows_to_keep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc024933-36d7-4b5a-83fb-28e3ef120f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_aligned_sample(file_path, rows_to_skip):\n",
    "    return pd.read_csv(file_path, skiprows=rows_to_skip, low_memory=False)\n",
    "\n",
    "# Read all files using the same rows\n",
    "sampled_data = {\n",
    "    'train_numerical': read_aligned_sample('train_numeric.csv', rows_to_skip),\n",
    "    'train_categorical': read_aligned_sample('train_categorical.csv', rows_to_skip),\n",
    "    'train_date': read_aligned_sample('train_date.csv', rows_to_skip)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23b1a3f-232d-4834-b9fe-969437332948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_numerical: (99906, 970), First ID: 70\n",
      "train_categorical: (99906, 2141), First ID: 70\n",
      "train_date: (99906, 1157), First ID: 70\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the sampled numerical, categorical and date data\n",
    "for key, df in sampled_data.items():\n",
    "    print(f\"{key}: {df.shape}, First ID: {df.iloc[0, 0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "396a743f-161e-40e6-83f6-fe06e6f38719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save\n",
    "pd.Series(rows_to_keep).to_csv(\"train_rows_to_keep.csv\", index=False, header=[\"row_index\"])\n",
    "\n",
    "# Load back\n",
    "rows_to_keep_loaded = pd.read_csv(\"train_rows_to_keep.csv\")[\"row_index\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db917a0-a61b-424b-a9bb-baa4c2503816",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = 1184687  # adjust to the dataset size (including header row)\n",
    "\n",
    "# All possible data rows (excluding header row)\n",
    "all_rows = set(range(1, total_rows))\n",
    "\n",
    "# Skip everything that is not in rows_to_keep\n",
    "rows_to_skip = sorted(all_rows - set(rows_to_keep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac17042a-218f-463b-b95a-1fbe33cd294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.088</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  \\\n",
       "0   70     0.062     0.071    -0.179    -0.216     0.161      0.025   \n",
       "1  191       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2  268       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "3  286       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "4  295    -0.049    -0.071    -0.015     0.003    -0.013      0.116   \n",
       "\n",
       "   L0_S0_F12  L0_S0_F14  L0_S0_F16  ...  L3_S50_F4245  L3_S50_F4247  \\\n",
       "0     -0.022     -0.112     -0.174  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4      0.008      0.088     -0.133  ...           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  \\\n",
       "0           NaN           NaN           NaN           0.0           0.0   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4260  L3_S51_F4262  Response  \n",
       "0           0.0           0.0         0  \n",
       "1           NaN           NaN         0  \n",
       "2           NaN           NaN         0  \n",
       "3           NaN           NaN         0  \n",
       "4           NaN           NaN         0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_files = {\n",
    "    'train_numerical': 'train_numeric.csv',\n",
    "    'train_categorical': 'train_categorical.csv',\n",
    "    'train_date': 'train_date.csv'\n",
    "}\n",
    "\n",
    "preview_data = {}\n",
    "for name, path in preview_files.items():\n",
    "    preview_data[name] = pd.read_csv(\n",
    "        path,\n",
    "        skiprows=rows_to_skip,  # ensure alignment\n",
    "        nrows=100,              # preview only 100 rows\n",
    "        low_memory=False\n",
    "    )\n",
    "    \n",
    "# Display nicely in notebook (return df objects)\n",
    "preview_data['train_numerical'].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac4ed76-4e58-48c3-8c5d-dcb27a4502d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "0   70        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1  191        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2  268        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3  286        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4  295        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   L0_S2_F37  L0_S2_F39  L0_S2_F41  ...  L3_S49_F4225  L3_S49_F4227  \\\n",
       "0        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  L3_S49_F4235  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 2141 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_data['train_categorical'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297fe95a-d9b2-441a-bbb5-4ac1e410c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>187.57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.97</td>\n",
       "      <td>188.97</td>\n",
       "      <td>188.97</td>\n",
       "      <td>188.97</td>\n",
       "      <td>188.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>702.76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  \\\n",
       "0   70    187.57    187.57    187.57    187.57    187.57     187.57   \n",
       "1  191       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2  268       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "3  286       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "4  295    702.76    702.76    702.76    702.76    702.76     702.76   \n",
       "\n",
       "   L0_S0_D13  L0_S0_D15  L0_S0_D17  ...  L3_S50_D4246  L3_S50_D4248  \\\n",
       "0     187.57     187.57     187.57  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4     702.76     702.76     702.76  ...           NaN           NaN   \n",
       "\n",
       "   L3_S50_D4250  L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  \\\n",
       "0           NaN           NaN           NaN        188.97        188.97   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_D4259  L3_S51_D4261  L3_S51_D4263  \n",
       "0        188.97        188.97        188.97  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1157 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_data['train_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6103c8-a809-479d-965f-74c9bf1fc097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaNs in train_numerical: 78404853\n",
      "Total NaNs in train_categorical: 208099075\n",
      "Total NaNs in train_date: 94969494\n"
     ]
    }
   ],
   "source": [
    "#Count Total NaNs in Each Reduced DataFrame\n",
    "for name, df in sampled_data.items():\n",
    "    total_nans = df.isna().sum().sum()\n",
    "    print(f\"Total NaNs in {name}: {total_nans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6254da1-0de0-4b1f-9e03-1451494317da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S0_F0</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S0_F2</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S0_F4</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S0_F6</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>L3_S51_F4256</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>L3_S51_F4258</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>L3_S51_F4260</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>L3_S51_F4262</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Response</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  NaN_count\n",
       "0              Id          0\n",
       "1        L0_S0_F0      43130\n",
       "2        L0_S0_F2      43130\n",
       "3        L0_S0_F4      43130\n",
       "4        L0_S0_F6      43130\n",
       "..            ...        ...\n",
       "965  L3_S51_F4256      94905\n",
       "966  L3_S51_F4258      94905\n",
       "967  L3_S51_F4260      94905\n",
       "968  L3_S51_F4262      94905\n",
       "969      Response          0\n",
       "\n",
       "[970 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count NaNs Per Column\n",
    "nan_counts = {}\n",
    "for name, df in sampled_data.items():\n",
    "    nan_counts[name] = (\n",
    "        df.isna().sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"column\", 0: \"NaN_count\"})\n",
    "    )\n",
    "nan_counts[\"train_numerical\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721bb2bf-be08-407d-b69e-0f1f0be8d939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S1_F25</td>\n",
       "      <td>99905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S1_F27</td>\n",
       "      <td>99905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S1_F29</td>\n",
       "      <td>99905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S1_F31</td>\n",
       "      <td>99905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>L3_S49_F4234</td>\n",
       "      <td>99904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>L3_S49_F4235</td>\n",
       "      <td>99904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>L3_S49_F4237</td>\n",
       "      <td>99904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>L3_S49_F4239</td>\n",
       "      <td>99904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>L3_S49_F4240</td>\n",
       "      <td>99904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  NaN_count\n",
       "0               Id          0\n",
       "1        L0_S1_F25      99905\n",
       "2        L0_S1_F27      99905\n",
       "3        L0_S1_F29      99905\n",
       "4        L0_S1_F31      99905\n",
       "...            ...        ...\n",
       "2136  L3_S49_F4234      99904\n",
       "2137  L3_S49_F4235      99904\n",
       "2138  L3_S49_F4237      99904\n",
       "2139  L3_S49_F4239      99904\n",
       "2140  L3_S49_F4240      99904\n",
       "\n",
       "[2141 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN counts for categorical \n",
    "nan_counts[\"train_categorical\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3695211-407b-4062-953f-f41185de3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S0_D1</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S0_D3</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S0_D5</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S0_D7</td>\n",
       "      <td>43130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>L3_S51_D4255</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>L3_S51_D4257</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>L3_S51_D4259</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>L3_S51_D4261</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>L3_S51_D4263</td>\n",
       "      <td>94905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  NaN_count\n",
       "0               Id          0\n",
       "1         L0_S0_D1      43130\n",
       "2         L0_S0_D3      43130\n",
       "3         L0_S0_D5      43130\n",
       "4         L0_S0_D7      43130\n",
       "...            ...        ...\n",
       "1152  L3_S51_D4255      94905\n",
       "1153  L3_S51_D4257      94905\n",
       "1154  L3_S51_D4259      94905\n",
       "1155  L3_S51_D4261      94905\n",
       "1156  L3_S51_D4263      94905\n",
       "\n",
       "[1157 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN counts for date\n",
    "nan_counts[\"train_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78fc6d3b-5c68-443f-b591-e381cbf1347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_numerical:\n",
      "  Rows with ≥1 NaN: 99906\n",
      "  Rows with all NaN: 0\n",
      "\n",
      "train_categorical:\n",
      "  Rows with ≥1 NaN: 99906\n",
      "  Rows with all NaN: 0\n",
      "\n",
      "train_date:\n",
      "  Rows with ≥1 NaN: 99906\n",
      "  Rows with all NaN: 0\n"
     ]
    }
   ],
   "source": [
    "#Count Rows With Any or All NaNs\n",
    "for name, df in sampled_data.items():\n",
    "    rows_with_any_nan = df.isna().any(axis=1).sum()\n",
    "    rows_with_all_nan = df.isna().all(axis=1).sum()\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Rows with ≥1 NaN: {rows_with_any_nan}\")\n",
    "    print(f\"  Rows with all NaN: {rows_with_all_nan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05314e3d-1325-43a4-87b6-a8540b00ad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "      <th>NaN_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S0_F0</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S0_F2</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S0_F4</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S0_F6</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>L3_S51_F4256</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>L3_S51_F4258</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>L3_S51_F4260</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>L3_S51_F4262</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Response</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  NaN_count    NaN_pct\n",
       "0              Id          0   0.000000\n",
       "1        L0_S0_F0      43130  43.170580\n",
       "2        L0_S0_F2      43130  43.170580\n",
       "3        L0_S0_F4      43130  43.170580\n",
       "4        L0_S0_F6      43130  43.170580\n",
       "..            ...        ...        ...\n",
       "965  L3_S51_F4256      94905  94.994295\n",
       "966  L3_S51_F4258      94905  94.994295\n",
       "967  L3_S51_F4260      94905  94.994295\n",
       "968  L3_S51_F4262      94905  94.994295\n",
       "969      Response          0   0.000000\n",
       "\n",
       "[970 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of NaN counts for train_numerical\n",
    "nan_counts_numeric = (\n",
    "    sampled_data['train_numerical'].isna().sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\", 0: \"NaN_count\"})\n",
    ")\n",
    "\n",
    "nan_counts_numeric[\"NaN_pct\"] = nan_counts_numeric[\"NaN_count\"] / len(sampled_data['train_numerical']) * 100\n",
    "nan_counts_numeric\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea26d5d-8be9-42f3-bd14-a019d81a1b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "      <th>NaN_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S1_F25</td>\n",
       "      <td>99905</td>\n",
       "      <td>99.998999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S1_F27</td>\n",
       "      <td>99905</td>\n",
       "      <td>99.998999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S1_F29</td>\n",
       "      <td>99905</td>\n",
       "      <td>99.998999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S1_F31</td>\n",
       "      <td>99905</td>\n",
       "      <td>99.998999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>L3_S49_F4234</td>\n",
       "      <td>99904</td>\n",
       "      <td>99.997998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>L3_S49_F4235</td>\n",
       "      <td>99904</td>\n",
       "      <td>99.997998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>L3_S49_F4237</td>\n",
       "      <td>99904</td>\n",
       "      <td>99.997998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>L3_S49_F4239</td>\n",
       "      <td>99904</td>\n",
       "      <td>99.997998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>L3_S49_F4240</td>\n",
       "      <td>99904</td>\n",
       "      <td>99.997998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2141 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  NaN_count    NaN_pct\n",
       "0               Id          0   0.000000\n",
       "1        L0_S1_F25      99905  99.998999\n",
       "2        L0_S1_F27      99905  99.998999\n",
       "3        L0_S1_F29      99905  99.998999\n",
       "4        L0_S1_F31      99905  99.998999\n",
       "...            ...        ...        ...\n",
       "2136  L3_S49_F4234      99904  99.997998\n",
       "2137  L3_S49_F4235      99904  99.997998\n",
       "2138  L3_S49_F4237      99904  99.997998\n",
       "2139  L3_S49_F4239      99904  99.997998\n",
       "2140  L3_S49_F4240      99904  99.997998\n",
       "\n",
       "[2141 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_counts_categorical = (\n",
    "    sampled_data['train_categorical'].isna().sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\", 0: \"NaN_count\"})\n",
    ")\n",
    "\n",
    "nan_counts_categorical[\"NaN_pct\"] = nan_counts_categorical[\"NaN_count\"] / len(sampled_data['train_categorical']) * 100\n",
    "nan_counts_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e08490-92bb-4c33-90a0-787770e1cd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>NaN_count</th>\n",
       "      <th>NaN_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S0_D1</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S0_D3</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S0_D5</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S0_D7</td>\n",
       "      <td>43130</td>\n",
       "      <td>43.170580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>L3_S51_D4255</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>L3_S51_D4257</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>L3_S51_D4259</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>L3_S51_D4261</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>L3_S51_D4263</td>\n",
       "      <td>94905</td>\n",
       "      <td>94.994295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  NaN_count    NaN_pct\n",
       "0               Id          0   0.000000\n",
       "1         L0_S0_D1      43130  43.170580\n",
       "2         L0_S0_D3      43130  43.170580\n",
       "3         L0_S0_D5      43130  43.170580\n",
       "4         L0_S0_D7      43130  43.170580\n",
       "...            ...        ...        ...\n",
       "1152  L3_S51_D4255      94905  94.994295\n",
       "1153  L3_S51_D4257      94905  94.994295\n",
       "1154  L3_S51_D4259      94905  94.994295\n",
       "1155  L3_S51_D4261      94905  94.994295\n",
       "1156  L3_S51_D4263      94905  94.994295\n",
       "\n",
       "[1157 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_counts_date = (\n",
    "    sampled_data['train_date'].isna().sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\", 0: \"NaN_count\"})\n",
    ")\n",
    "\n",
    "nan_counts_date[\"NaN_pct\"] = nan_counts_date[\"NaN_count\"] / len(sampled_data['train_date']) * 100\n",
    "nan_counts_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed6dd2ef-c13d-4ece-97db-c7917c9cc7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NaNs per row numerical: 784.79\n",
      "Average NaNs per row categorical: 2082.95\n",
      "Average NaNs per row date: 950.59\n"
     ]
    }
   ],
   "source": [
    "# Average NaNs per row (how many missing values each row has on average) \n",
    "\n",
    "nan_avg_per_row_numerical = sampled_data['train_numerical'].isna().sum(axis=1).mean()\n",
    "nan_avg_per_row_categorical = sampled_data['train_categorical'].isna().sum(axis=1).mean()\n",
    "nan_avg_per_row_date = sampled_data['train_date'].isna().sum(axis=1).mean()\n",
    "print(\"Average NaNs per row numerical:\", nan_avg_per_row_numerical.round(2))\n",
    "print(\"Average NaNs per row categorical:\", nan_avg_per_row_categorical.round(2))\n",
    "print(\"Average NaNs per row date:\", nan_avg_per_row_date.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac79c26-d775-4d98-adf6-271509916363",
   "metadata": {},
   "source": [
    "## The data checks shows that there is a large number of missing values in the sampled 100,000 data frame for all three files (numerical, categorical, and date).  This will pose a significant issue for logistic regression which is sensitive to NaN or missing values. Must drop rows that have lots of NaNs, and/or use PCA and/or L1 regression that will reduce factors that are not important to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45128c95-fa91-493f-bc88-9ef03f846713",
   "metadata": {},
   "source": [
    "# Prepare the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2ab8b99-3db1-451b-b1c4-e634cd6402ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows_test = 1183748  # Total rows including header\n",
    "sample_size_test = 30000\n",
    "\n",
    "# Generate a shared random sample of row indices to KEEP (excluding the header row)\n",
    "rows_to_keep_test = sorted(np.random.choice(np.arange(1, total_rows_test), size=sample_size_test, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77e77eb0-5ba7-45c4-8679-7c73ab617297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_numerical: (30001, 969), First ID: 40\n",
      "test_categorical: (30001, 2141), First ID: 40\n",
      "test_date: (30001, 1157), First ID: 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4243</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 969 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  \\\n",
       "0   40    -0.068    -0.101    -0.015    -0.052     0.118      0.070   \n",
       "1  150    -0.082    -0.078    -0.215    -0.179     0.161      0.025   \n",
       "2  172     0.056     0.071    -0.197    -0.179     0.118      0.025   \n",
       "3  222       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "4  369       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "   L0_S0_F12  L0_S0_F14  L0_S0_F16  ...  L3_S50_F4243  L3_S50_F4245  \\\n",
       "0      0.015      0.128     -0.061  ...           NaN           NaN   \n",
       "1      0.008      0.008     -0.005  ...           NaN           NaN   \n",
       "2     -0.015     -0.112      0.000  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4247  L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4258  L3_S51_F4260  L3_S51_F4262  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 969 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All data rows (excluding header) are 1 to total_rows-1\n",
    "all_rows = set(range(1, total_rows_test))\n",
    "rows_to_skip_test = sorted(all_rows - set(rows_to_keep_test))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_aligned_sample(file_path, rows_to_skip_test):\n",
    "    return pd.read_csv(file_path, skiprows=rows_to_skip_test, low_memory=False)\n",
    "\n",
    "# Read all files using the same rows\n",
    "sampled_data_test = {\n",
    "    'test_numerical': read_aligned_sample('test_numeric.csv', rows_to_skip_test),\n",
    "    'test_categorical': read_aligned_sample('test_categorical.csv', rows_to_skip_test),\n",
    "    'test_date': read_aligned_sample('test_date.csv', rows_to_skip_test)\n",
    "}\n",
    "\n",
    "for key, df in sampled_data_test.items():\n",
    "    print(f\"{key}: {df.shape}, First ID: {df.iloc[0, 0]}\")\n",
    "\n",
    "# Save\n",
    "pd.Series(rows_to_keep_test).to_csv(\"test_rows_to_keep.csv\", index=False, header=[\"row_index\"])\n",
    "\n",
    "# Load back\n",
    "rows_to_keep_test_loaded = pd.read_csv(\"test_rows_to_keep.csv\")[\"row_index\"].tolist()\n",
    "\n",
    "total_rows = 1183748  # adjust to the dataset size (including header row)\n",
    "\n",
    "# All possible data rows (excluding header row)\n",
    "all_rows = set(range(1, total_rows_test))\n",
    "\n",
    "# Skip everything that is not in rows_to_keep\n",
    "rows_to_skip = sorted(all_rows - set(rows_to_keep_test))\n",
    "\n",
    "preview_files = {\n",
    "    'test_numerical': 'test_numeric.csv',\n",
    "    'test_categorical': 'test_categorical.csv',\n",
    "    'test_date': 'test_date.csv'\n",
    "}\n",
    "\n",
    "preview_data = {}\n",
    "for name, path in preview_files.items():\n",
    "    preview_data[name] = pd.read_csv(\n",
    "        path,\n",
    "        skiprows=rows_to_skip_test,  # ensure alignment\n",
    "        nrows=100,              # preview only 100 rows\n",
    "        low_memory=False\n",
    "    )\n",
    "    \n",
    "# Display nicely in notebook (return df objects for test_numeric)\n",
    "preview_data['test_numerical'].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62133709-407b-4e54-9576-aff8896037a3",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f6707d9-112c-478a-ae00-8af376b74845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "0   40        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1  150        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2  172        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3  222        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4  369        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   L0_S2_F37  L0_S2_F39  L0_S2_F41  ...  L3_S49_F4225  L3_S49_F4227  \\\n",
       "0        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  L3_S49_F4235  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 2141 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display nicely in notebook (return df objects for test_categorical)\n",
    "preview_data['test_categorical'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2af31cf-5d23-41f7-9faa-e263d1d6d52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>247.44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>218.55</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>169.36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  \\\n",
       "0   40    247.44    247.44    247.44    247.44    247.44     247.44   \n",
       "1  150    218.55    218.55    218.55    218.55    218.55     218.55   \n",
       "2  172    169.36    169.36    169.36    169.36    169.36     169.36   \n",
       "3  222       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "4  369       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "   L0_S0_D13  L0_S0_D15  L0_S0_D17  ...  L3_S50_D4246  L3_S50_D4248  \\\n",
       "0     247.44     247.44     247.44  ...           NaN           NaN   \n",
       "1     218.55     218.55     218.55  ...           NaN           NaN   \n",
       "2     169.36     169.36     169.36  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "   L3_S50_D4250  L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_D4259  L3_S51_D4261  L3_S51_D4263  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1157 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display nicely in notebook (return df objects for test_date)\n",
    "preview_data['test_date'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e729f-72b2-4310-b2d7-c6e86d0807f4",
   "metadata": {},
   "source": [
    "## I am able to sample 30001 rows from the test datasets. This will be used as the test data in the test-train split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dbe91c8-32c5-4095-a841-be62a2870398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "num_df = sampled_data['train_numerical'].copy()\n",
    "cat_df = sampled_data['train_categorical'].copy()\n",
    "date_df = sampled_data['train_date'].copy()\n",
    "\n",
    "# Ensure Id exists and is unique \n",
    "for df in [num_df, cat_df, date_df]:\n",
    "    if 'Id' in df.columns:\n",
    "        df.set_index('Id', inplace=True)\n",
    "\n",
    "# Target ('Response' in train_numeric)\n",
    "target_col = 'Response' if 'Response' in num_df.columns else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cced9ad-0bdd-41cc-a2e4-dd5535b64481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.211915</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.211982</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>0.094713</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.164182</td>\n",
       "      <td>-0.566</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.104602</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.115231</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S0_F18</th>\n",
       "      <td>56776.0</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.112645</td>\n",
       "      <td>-0.425</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std    min    25%    50%    75%    max\n",
       "L0_S0_F0   56776.0  0.000070  0.080374 -0.382 -0.049  0.003  0.056  0.265\n",
       "L0_S0_F2   56776.0 -0.000069  0.093175 -0.399 -0.056  0.004  0.063  0.295\n",
       "L0_S0_F4   56776.0  0.001090  0.211915 -0.415 -0.179 -0.033  0.294  0.567\n",
       "L0_S0_F6   56776.0  0.001066  0.211982 -0.397 -0.179 -0.034  0.294  0.566\n",
       "L0_S0_F8   56776.0 -0.000521  0.094713 -0.447 -0.056  0.031  0.074  0.335\n",
       "L0_S0_F10  56776.0  0.001437  0.164182 -0.566 -0.066  0.070  0.116  0.252\n",
       "L0_S0_F12  56776.0 -0.000007  0.019424 -0.052 -0.015  0.000  0.015  0.089\n",
       "L0_S0_F14  56776.0  0.000017  0.104602 -0.232 -0.072 -0.032  0.088  0.488\n",
       "L0_S0_F16  56776.0  0.000164  0.115231 -0.398 -0.082  0.000  0.076  0.490\n",
       "L0_S0_F18  56776.0  0.000827  0.112645 -0.425 -0.078  0.002  0.077  0.473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2181</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2184</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2187</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2190</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2193</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2196</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2199</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2202</th>\n",
       "      <td>0.998849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2718</th>\n",
       "      <td>0.998178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2724</th>\n",
       "      <td>0.998178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing_pct\n",
       "L1_S25_F2181     0.998849\n",
       "L1_S25_F2184     0.998849\n",
       "L1_S25_F2187     0.998849\n",
       "L1_S25_F2190     0.998849\n",
       "L1_S25_F2193     0.998849\n",
       "L1_S25_F2196     0.998849\n",
       "L1_S25_F2199     0.998849\n",
       "L1_S25_F2202     0.998849\n",
       "L1_S25_F2718     0.998178\n",
       "L1_S25_F2724     0.998178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>T1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>T32</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>T1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>T32</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>T1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>T32</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique  top freq\n",
       "L0_S1_F25     1      1   T1    1\n",
       "L0_S1_F27     1      1   T9    1\n",
       "L0_S1_F29     1      1   T1    1\n",
       "L0_S1_F31     1      1   T9    1\n",
       "L0_S2_F33    26      1   T1   26\n",
       "L0_S2_F35    26      4  T32   18\n",
       "L0_S2_F37    26      1   T1   26\n",
       "L0_S2_F39    26      4  T32   18\n",
       "L0_S2_F41    26      1   T1   26\n",
       "L0_S2_F43    26      4  T32   18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_S25_F2057</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1422</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S30_F3672</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1432</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1430</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1429</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1427</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1425</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1424</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_S24_F1420</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              missing_pct\n",
       "L1_S25_F2057          1.0\n",
       "L1_S24_F1422          1.0\n",
       "L3_S30_F3672          1.0\n",
       "L1_S24_F1432          1.0\n",
       "L1_S24_F1430          1.0\n",
       "L1_S24_F1429          1.0\n",
       "L1_S24_F1427          1.0\n",
       "L1_S24_F1425          1.0\n",
       "L1_S24_F1424          1.0\n",
       "L1_S24_F1420          1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numeric summary (exclude Id/target)\n",
    "num_cols = [c for c in num_df.columns if c != target_col]\n",
    "num_summary = num_df[num_cols].describe().T\n",
    "num_missing = num_df[num_cols].isna().mean().sort_values(ascending=False).to_frame('missing_pct')\n",
    "\n",
    "# Categorical summary (top categories)\n",
    "cat_cols = cat_df.columns.tolist()\n",
    "cat_summary = cat_df[cat_cols].describe(include='object').T  # count, unique, top, freq\n",
    "cat_missing = cat_df[cat_cols].isna().mean().sort_values(ascending=False).to_frame('missing_pct')\n",
    "\n",
    "display(num_summary.head(10))\n",
    "display(num_missing.head(10))\n",
    "display(cat_summary.head(10))\n",
    "display(cat_missing.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54f303-a9d5-49a9-bab2-1bc18c954cd3",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Categorical to numerical for both the test and train data: One hot encoder\n",
    "- Numerical data: imputation, standard scaling (since the data sets are separate don't have to worry to do it after the test train split. Can perform the standard scaling on each test and train data set)\n",
    "- Compare against minimum – maximum scaling\n",
    "- Unbalanced data - SMOTE (Synthetic Minority Over-sampling Technique) will be investigated later, if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9caabca5-96be-4e32-ab01-364d47cea0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Grab the sampled dataframes\n",
    "train_num = sampled_data['train_numerical'].copy()\n",
    "train_cat = sampled_data['train_categorical'].copy()\n",
    "\n",
    "test_num  = sampled_data_test['test_numerical'].copy()\n",
    "test_cat  = sampled_data_test['test_categorical'].copy()\n",
    "\n",
    "# Set 'Id' as index if present (Bosch has Id as first col)\n",
    "for df in (train_num, train_cat, test_num, test_cat):\n",
    "    if 'Id' in df.columns:\n",
    "        df.set_index('Id', inplace=True)\n",
    "\n",
    "# Separate target and drop it from numeric features \n",
    "assert 'Response' in train_num.columns, \"Expected 'Response' in train_numerical\"\n",
    "y_train = train_num['Response'].copy()\n",
    "train_num = train_num.drop(columns=['Response'])\n",
    "\n",
    "# Align columns & drop all-NaN columns safely\n",
    "# Ensure test has all train columns (add missing as NaN)\n",
    "test_num = test_num.reindex(columns=train_num.columns, fill_value=np.nan)\n",
    "test_cat = test_cat.reindex(columns=train_cat.columns, fill_value=np.nan)\n",
    "\n",
    "# Drop numeric columns that are ALL NaN in TRAIN to avoid imputer errors\n",
    "all_nan_num_cols = train_num.columns[train_num.isna().all()].tolist()\n",
    "if all_nan_num_cols:\n",
    "    train_num = train_num.drop(columns=all_nan_num_cols)\n",
    "    test_num  = test_num.drop(columns=all_nan_num_cols)\n",
    "\n",
    "# Keep categorical columns (they can be all-NaN; impute a constant)\n",
    "# But if a column is entirely missing in BOTH train and test, drop it.\n",
    "all_nan_cat_cols = train_cat.columns[(train_cat.isna().all()) & (test_cat.isna().all())].tolist()\n",
    "if all_nan_cat_cols:\n",
    "    train_cat = train_cat.drop(columns=all_nan_cat_cols)\n",
    "    test_cat  = test_cat.drop(columns=all_nan_cat_cols)\n",
    "\n",
    "# Feature lists\n",
    "numeric_features = train_num.columns.tolist()\n",
    "categorical_features = train_cat.columns.tolist()\n",
    "\n",
    "# Combine into X dataframes\n",
    "X_train = pd.concat([train_num, train_cat], axis=1)\n",
    "X_test  = pd.concat([test_num,  test_cat],  axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a4378-ab63-4aef-af38-9f95c9f1c635",
   "metadata": {},
   "source": [
    "## All-NaN numeric columns are dropped before fitting to avoid SimpleImputer errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e7261ec-d8ba-4fbe-bb0c-80cf982b0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before fitting the pipelines\n",
    "X_train[numeric_features] = X_train[numeric_features].astype('float32')\n",
    "X_test[numeric_features]  = X_test[numeric_features].astype('float32')\n",
    "\n",
    "\n",
    "# Build transformers\n",
    "# OneHotEncoder: keep sparse to save memory; handle versions with/without sparse_output\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=True, min_frequency=5, max_categories=500)\n",
    "except TypeError:\n",
    "    # for older scikit-learn versions\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=True, min_frequency=5, max_categories=500)\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "    ('ohe', ohe)\n",
    "])\n",
    "\n",
    "num_pipe_standard = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())  # mean/var from TRAIN, then apply to TEST\n",
    "])\n",
    "\n",
    "num_pipe_minmax = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())    # min/max from TRAIN, then apply to TEST\n",
    "])\n",
    "\n",
    "# ColumnTransformers (two variants to compare)\n",
    "preproc_standard = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe_standard, numeric_features),\n",
    "        ('cat', cat_pipe,          categorical_features)\n",
    "    ],\n",
    "    remainder='drop',  # keep only specified columns\n",
    "    sparse_threshold=1.0,  # favor sparse output if mostly OHE\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "preproc_minmax = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe_minmax,   numeric_features),\n",
    "        ('cat', cat_pipe,          categorical_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc72079-0230-4d74-bbda-48873979714e",
   "metadata": {},
   "source": [
    "## Categorical imputation uses a constant label (\"MISSING\") so all-missing columns still produce a single OHE column (rather than erroring).\n",
    "## By setting handle_unknown='ignore' allows the test set have unseen categories without crashing.\n",
    "## Two preprocessors (Standard vs Min-Max) are trained independently to compare downstream model performance easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c77a7073-e78c-46cc-930e-4aff04b68cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transformed matrices ===\n",
      "X_train_std: shape=(99906, 4338), sparse=True, density=0.5894421392346704\n",
      "X_test_std : shape=(30001, 4338), sparse=True, density=0.5894403335472036\n",
      "X_train_mm : shape=(99906, 4338), sparse=True, density=0.5828739965313822\n",
      "X_test_mm  : shape=(30001, 4338), sparse=True, density=0.5828712886456882\n"
     ]
    }
   ],
   "source": [
    "# Fit on TRAIN, transform TRAIN & TEST\n",
    "X_train_std = preproc_standard.fit_transform(X_train, y_train)\n",
    "X_test_std  = preproc_standard.transform(X_test)\n",
    "\n",
    "X_train_mm  = preproc_minmax.fit_transform(X_train, y_train)\n",
    "X_test_mm   = preproc_minmax.transform(X_test)\n",
    "\n",
    "# Utilities: feature names, quick comparison\n",
    "def get_feature_names(transformer):\n",
    "    # Works on sklearn >= 1.0\n",
    "    try:\n",
    "        return transformer.get_feature_names_out().tolist()\n",
    "    except Exception:\n",
    "        # Fallback best-effort for older versions:\n",
    "        names = []\n",
    "        # Numeric original names:\n",
    "        names.extend([f\"num__{c}\" for c in numeric_features])\n",
    "        # OHE category names (not exact without access to ohe categories_)\n",
    "        names.extend([f\"cat__{c}__<levels>\" for c in categorical_features])\n",
    "        return names\n",
    "\n",
    "std_feat_names = get_feature_names(preproc_standard)\n",
    "mm_feat_names  = get_feature_names(preproc_minmax)\n",
    "\n",
    "def describe_matrix(name, mat):\n",
    "    shape = (mat.shape[0], mat.shape[1])\n",
    "    is_sparse = sparse.issparse(mat)\n",
    "    density = None\n",
    "    if is_sparse:\n",
    "        density = mat.nnz / (mat.shape[0] * mat.shape[1])\n",
    "    print(f\"{name}: shape={shape}, sparse={is_sparse}, density={density if density is not None else 'n/a'}\")\n",
    "\n",
    "print(\"\\n=== Transformed matrices ===\")\n",
    "describe_matrix(\"X_train_std\", X_train_std)\n",
    "describe_matrix(\"X_test_std \", X_test_std)\n",
    "describe_matrix(\"X_train_mm \", X_train_mm)\n",
    "describe_matrix(\"X_test_mm  \", X_test_mm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad6659-88b0-4f67-83a8-2aa6e5da9554",
   "metadata": {},
   "source": [
    "## Fit on train, apply to test: both imputers, scalers, and the OHE learn from train only, preventing leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097b7f18-f3a1-4bfd-8227-0512fc451262",
   "metadata": {},
   "source": [
    "## Feature selection/engineering\n",
    "- Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "937bf7b3-5380-48f8-95f0-d8e834827861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruncatedSVD: tried 300 comps; 300 comps reach ~0.750 cumulative variance.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from scipy import sparse\n",
    "\n",
    "# choose component cap\n",
    "n_features = X_train_std.shape[1]\n",
    "n_components_try = max(2, min(300, n_features - 1))\n",
    "evr_target = 0.95\n",
    "\n",
    "if sparse.issparse(X_train_std):\n",
    "    # SVD path (sparse)\n",
    "    svd = TruncatedSVD(n_components=n_components_try, random_state=42)\n",
    "    X_train_pcs = svd.fit_transform(X_train_std)\n",
    "    X_test_pcs  = svd.transform(X_test_std)\n",
    "    evr = svd.explained_variance_ratio_\n",
    "    cum_evr = np.cumsum(evr)\n",
    "    k = int(np.searchsorted(cum_evr, evr_target) + 1)\n",
    "    k = max(2, min(k, n_components_try))\n",
    "    model_used = \"TruncatedSVD\"\n",
    "else:\n",
    "    # PCA path (dense)\n",
    "    # randomized solver is fast for many features/samples\n",
    "    pca = PCA(n_components=n_components_try, svd_solver='randomized', random_state=42)\n",
    "    X_train_pcs = pca.fit_transform(X_train_std)\n",
    "    X_test_pcs  = pca.transform(X_test_std)\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    cum_evr = np.cumsum(evr)\n",
    "    k = int(np.searchsorted(cum_evr, evr_target) + 1)\n",
    "    k = max(2, min(k, n_components_try))\n",
    "    model_used = \"PCA (randomized)\"\n",
    "\n",
    "print(f\"{model_used}: tried {n_components_try} comps; \"\n",
    "      f\"{k} comps reach ~{cum_evr[k-1]:.3f} cumulative variance.\")\n",
    "\n",
    "# keep first k\n",
    "X_train_pca_std = X_train_pcs[:, :k]\n",
    "X_test_pca_std  = X_test_pcs[:, :k]\n",
    "\n",
    "pc_cols = [f\"PC{i}\" for i in range(1, k+1)]\n",
    "train_ids = (sampled_data['train_numerical'].set_index('Id').index\n",
    "             if 'Id' in sampled_data['train_numerical'].columns else None)\n",
    "test_ids  = (sampled_data_test['test_numerical'].set_index('Id').index\n",
    "             if 'Id' in sampled_data_test['test_numerical'].columns else None)\n",
    "\n",
    "train_pca_std_df = pd.DataFrame(X_train_pca_std, index=train_ids, columns=pc_cols)\n",
    "test_pca_std_df  = pd.DataFrame(X_test_pca_std,  index=test_ids,  columns=pc_cols)\n",
    "\n",
    "# scree plots\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(np.arange(1, len(evr)+1), evr, marker='o')\n",
    "plt.title(f\"Scree: EVR per Component ({model_used})\")\n",
    "plt.xlabel(\"Component\"); plt.ylabel(\"EVR\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(np.arange(1, len(cum_evr)+1), cum_evr, marker='o')\n",
    "plt.axhline(evr_target, ls='--')\n",
    "plt.title(f\"Cumulative Explained Variance ({model_used})\")\n",
    "plt.xlabel(\"Component\"); plt.ylabel(\"Cumulative EVR\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08593a01-88da-469f-b669-fb4eb2b2b89e",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Logistic regression model - L1 regularization\n",
    "- Decision tree model (Tree depth (n=5))\n",
    "- Hyper parameter tuning for both logistic regression and decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e01b6cf8-7442-4140-8334-c27b113870a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Limit BLAS threads to avoid oversubscription (helps RAM/CPU thrash)\n",
    "# Got this hint from the internet\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import sparse\n",
    "\n",
    "# Reload sampled data\n",
    "train_num = sampled_data['train_numerical'].copy()\n",
    "train_cat = sampled_data['train_categorical'].copy()\n",
    "test_num  = sampled_data_test['test_numerical'].copy()\n",
    "test_cat  = sampled_data_test['test_categorical'].copy()\n",
    "\n",
    "for df in (train_num, train_cat, test_num, test_cat):\n",
    "    if 'Id' in df.columns:\n",
    "        df.set_index('Id', inplace=True)\n",
    "\n",
    "assert 'Response' in train_num.columns, \"Expected 'Response' in train_numerical\"\n",
    "y = train_num['Response'].astype(int)\n",
    "train_num = train_num.drop(columns=['Response'])\n",
    "\n",
    "# Align test columns to train columns\n",
    "test_num = test_num.reindex(columns=train_num.columns, fill_value=np.nan)\n",
    "test_cat = test_cat.reindex(columns=train_cat.columns, fill_value=np.nan)\n",
    "\n",
    "numeric_features = train_num.columns.tolist()\n",
    "categorical_features = train_cat.columns.tolist()\n",
    "\n",
    "X_train_raw = pd.concat([train_num, train_cat], axis=1)\n",
    "X_test_raw  = pd.concat([test_num,  test_cat],  axis=1)\n",
    "\n",
    "# OHE factory that reduces cardinality + returns sparse\n",
    "def make_ohe_slim():\n",
    "    try:\n",
    "        # Newer sklearn: group rare levels automatically\n",
    "        return OneHotEncoder(\n",
    "            handle_unknown='infrequent_if_exist',\n",
    "            min_frequency=10,            \n",
    "            sparse_output=True\n",
    "        )\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(\n",
    "                handle_unknown='ignore',\n",
    "                max_categories=50,\n",
    "                sparse=True\n",
    "            )\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(\n",
    "                handle_unknown='ignore',\n",
    "                sparse=True\n",
    "            )\n",
    "\n",
    "ohe_linear = make_ohe_slim()\n",
    "ohe_tree   = make_ohe_slim()\n",
    "\n",
    "# Preprocessors\n",
    "preproc_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler',  StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     ohe_linear)\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0   # always prefer sparse if any block is sparse\n",
    ")\n",
    "\n",
    "preproc_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     ohe_tree)\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb012d28-8a51-447d-81fb-8bbe1bf43a20",
   "metadata": {},
   "source": [
    "## I performed dimensionality reduced before the classifier (often best for OHE-heavy data) and reran the program and its still running after 12 hours without completing the kernal. I determined that the bottlenecks are: (1) refitting OHE+SVD inside every CV fold, (2) too many candidates/folds, and (3) using a heavy solver on high-dim data.\n",
    "## To make it run faster, I did the following: \n",
    "- Tune on a stratified subset (30k rows), then refit best params on the full 100k.\n",
    "- Use HalvingRandomSearchCV (successive halving) with 3-fold CV.\n",
    "- Shrink SVD to ~50 comps and n_iter=2.\n",
    "- Use L1 + liblinear (binary) after SVD (way faster than saga here).\n",
    "- For the tree, compress the categorical branch with OHE → SVD inside the ColumnTransformer (dramatically fewer features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3cb9103-e9ca-40b4-8b11-c7fdc3531189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Halving search (Logistic L1 + SVD) on 30k subset ===\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 8000\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 3\n",
      "n_resources: 8000\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 16000\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best AUC (tune): 0.9939996249765611\n",
      "Best params: {'clf__C': 0.013292918943162165, 'clf__class_weight': None, 'svd__n_components': 80}\n",
      "\n",
      "=== Halving search (Decision Tree + cat SVD) on 30k subset ===\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 8000\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 3\n",
      "n_resources: 8000\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 16000\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best AUC (tune): 0.782298893680855\n",
      "Best params: {'prep__cat_svd__svd__n_components': 30, 'clf__min_samples_split': 20, 'clf__min_samples_leaf': 10, 'clf__max_depth': 9, 'clf__class_weight': 'balanced'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>proba_logit_l1</th>\n",
       "      <th>proba_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.522942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.522942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.137962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  proba_logit_l1  proba_tree\n",
       "0   40        0.005025    0.522942\n",
       "1  150        0.005462    0.522942\n",
       "2  172        0.005210    0.000000\n",
       "3  222        0.004880    0.137962\n",
       "4  369        0.011620    0.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  \n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Pull sampled data \n",
    "train_num = sampled_data['train_numerical'].copy()\n",
    "train_cat = sampled_data['train_categorical'].copy()\n",
    "test_num  = sampled_data_test['test_numerical'].copy()\n",
    "test_cat  = sampled_data_test['test_categorical'].copy()\n",
    "\n",
    "for df in (train_num, train_cat, test_num, test_cat):\n",
    "    if 'Id' in df.columns:\n",
    "        df.set_index('Id', inplace=True)\n",
    "\n",
    "y = train_num['Response'].astype(int)\n",
    "train_num = train_num.drop(columns=['Response'])\n",
    "\n",
    "# Align test to train columns\n",
    "test_num = test_num.reindex(columns=train_num.columns, fill_value=np.nan)\n",
    "test_cat = test_cat.reindex(columns=train_cat.columns, fill_value=np.nan)\n",
    "\n",
    "numeric_features = train_num.columns.tolist()\n",
    "categorical_features = train_cat.columns.tolist()\n",
    "\n",
    "X_train_raw = pd.concat([train_num, train_cat], axis=1)\n",
    "X_test_raw  = pd.concat([test_num,  test_cat],  axis=1)\n",
    "\n",
    "# Slimmer OHE to cut width\n",
    "def make_ohe_slim():\n",
    "    try:\n",
    "        # Newer sklearn: group rare levels\n",
    "        return OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=10, sparse_output=True)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown='ignore', max_categories=50, sparse=True)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "\n",
    "# Pipelines (FAST)\n",
    "# (a) Logistic (L1) path: numeric (impute+scale) + categorical (OHE) to SVD(50) to L1 liblinear\n",
    "preproc_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler',  StandardScaler()),\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     make_ohe_slim()),\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "logit_pipe_fast = Pipeline([\n",
    "    ('prep', preproc_linear),\n",
    "    ('svd',  TruncatedSVD(n_components=50, n_iter=2, random_state=42)),\n",
    "    ('clf',  LogisticRegression(\n",
    "        penalty='l1', solver='liblinear',\n",
    "        max_iter=2000, tol=1e-3, random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# (b) Decision Tree path: numeric (impute) + categorical (OHE to SVD(50)) ; concat to DT\n",
    "preproc_tree_fast = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "        ]), numeric_features),\n",
    "        ('cat_svd', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     make_ohe_slim()),\n",
    "            ('svd',     TruncatedSVD(n_components=50, n_iter=2, random_state=42))\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "tree_pipe_fast = Pipeline([\n",
    "    ('prep', preproc_tree_fast),\n",
    "    ('clf',  DecisionTreeClassifier(max_depth=5, random_state=42))\n",
    "])\n",
    "\n",
    "# Make a 30k stratified tuning subset\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=min(30000, len(X_train_raw)), random_state=42)\n",
    "tune_idx, _ = next(sss.split(X_train_raw, y))\n",
    "X_tune = X_train_raw.iloc[tune_idx]\n",
    "y_tune = y.iloc[tune_idx]\n",
    "\n",
    "# HalvingRandomSearchCV (3-fold, small search)\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "scorer = 'roc_auc'\n",
    "\n",
    "logit_search = HalvingRandomSearchCV(\n",
    "    estimator=logit_pipe_fast,\n",
    "    param_distributions={\n",
    "        'clf__C': loguniform(1e-3, 1e0),             # 0.001..1\n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'svd__n_components': [30, 50, 80],\n",
    "    },\n",
    "    factor=2,              \n",
    "    min_resources=8000,    # start with 8k samples then ramp up\n",
    "    resource='n_samples',\n",
    "    cv=cv3,\n",
    "    n_jobs=1,              # safest for RAM\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "tree_search = HalvingRandomSearchCV(\n",
    "    estimator=tree_pipe_fast,\n",
    "    param_distributions={\n",
    "        'clf__max_depth': [3, 5, 7, 9],\n",
    "        'clf__min_samples_split': [2, 20, 100],\n",
    "        'clf__min_samples_leaf': [1, 10, 50],\n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        # Try a couple SVD sizes for the cat branch:\n",
    "        'prep__cat_svd__svd__n_components': [30, 50, 80],\n",
    "    },\n",
    "    factor=2,\n",
    "    min_resources=8000,\n",
    "    resource='n_samples',\n",
    "    cv=cv3,\n",
    "    n_jobs=1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"=== Halving search (Logistic L1 + SVD) on 30k subset ===\")\n",
    "logit_search.fit(X_tune, y_tune)\n",
    "print(\"Best AUC (tune):\", logit_search.best_score_)\n",
    "print(\"Best params:\", logit_search.best_params_)\n",
    "\n",
    "print(\"\\n=== Halving search (Decision Tree + cat SVD) on 30k subset ===\")\n",
    "tree_search.fit(X_tune, y_tune)\n",
    "print(\"Best AUC (tune):\", tree_search.best_score_)\n",
    "print(\"Best params:\", tree_search.best_params_)\n",
    "\n",
    "# ---------- 5) Refit best pipelines on FULL train, then predict TEST ----------\n",
    "best_logit = logit_search.best_estimator_\n",
    "best_tree  = tree_search.best_estimator_\n",
    "\n",
    "best_logit.fit(X_train_raw, y)\n",
    "best_tree.fit(X_train_raw, y)\n",
    "\n",
    "test_proba_logit = best_logit.predict_proba(X_test_raw)[:, 1]\n",
    "test_proba_tree  = best_tree.predict_proba(X_test_raw)[:, 1]\n",
    "\n",
    "test_ids = X_test_raw.index\n",
    "preds_df = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'proba_logit_l1': test_proba_logit,\n",
    "    'proba_tree':     test_proba_tree\n",
    "})\n",
    "preds_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e61716-e6a3-46a5-bfe4-a3e950b6026b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf6e7a-20b6-454a-a917-fd342f861a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40eb68c3-45b4-4b33-ae20-3265a2e7e11f",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- F1 Score\n",
    "- Precision\n",
    "- RMSE\n",
    "- Matthews Correlation Coefficient (MCC) between the predicted and the observed (will be done for the final project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f8beeeb-a502-4544-88bf-dda828fc4f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic L1 @ threshold=0.50 ===\n",
      "Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "RMSE (prob):  0.0750\n",
      "RMSE (label): 0.0752\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19869     0]\n",
      " [  113     0]]\n",
      "\n",
      "=== Logistic L1 (best-F1 th) @ threshold=0.10 ===\n",
      "Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "RMSE (prob):  0.0750\n",
      "RMSE (label): 0.0752\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19869     0]\n",
      " [  113     0]]\n",
      "\n",
      "=== Decision Tree (depth≈5) @ threshold=0.50 ===\n",
      "Precision: 0.0103 | Recall: 0.5575 | F1: 0.0202\n",
      "RMSE (prob):  0.3888\n",
      "RMSE (label): 0.5529\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[13811  6058]\n",
      " [   50    63]]\n",
      "\n",
      "=== Decision Tree (best-F1 th) @ threshold=0.90 ===\n",
      "Precision: 0.1004 | Recall: 0.2301 | F1: 0.1398\n",
      "RMSE (prob):  0.3888\n",
      "RMSE (label): 0.1265\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19636   233]\n",
      " [   87    26]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>RMSE_prob</th>\n",
       "      <th>RMSE_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree (best-F1 th)</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.100386</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.388838</td>\n",
       "      <td>0.126548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree (depth≈5)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>0.388838</td>\n",
       "      <td>0.552879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic L1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic L1 (best-F1 th)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.075200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Threshold  Precision        F1  RMSE_prob  \\\n",
       "0  Decision Tree (best-F1 th)        0.9   0.100386  0.139785   0.388838   \n",
       "1     Decision Tree (depth≈5)        0.5   0.010292  0.020212   0.388838   \n",
       "2                 Logistic L1        0.5   0.000000  0.000000   0.074961   \n",
       "3    Logistic L1 (best-F1 th)        0.1   0.000000  0.000000   0.074961   \n",
       "\n",
       "   RMSE_label  \n",
       "0    0.126548  \n",
       "1    0.552879  \n",
       "2    0.075200  \n",
       "3    0.075200  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    mean_squared_error, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Make a stratified hold-out split (20% for validation)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X_train_raw, y))\n",
    "\n",
    "X_tr, X_val = X_train_raw.iloc[train_idx], X_train_raw.iloc[val_idx]\n",
    "y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "# Evaluate a pipeline on the hold-out\n",
    "def evaluate_pipeline(pipeline, name: str, threshold: float = 0.5):\n",
    "    # clone to avoid mutating tuned objects\n",
    "    model = clone(pipeline)\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # hard preds at given threshold (use predict_proba for consistent thresholding)\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    y_pred  = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # metrics\n",
    "    precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall    = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1        = f1_score(y_val, y_pred, zero_division=0)\n",
    "\n",
    "    # RMSE probabilities and label computed:\n",
    "    rmse_prob  = np.sqrt(mean_squared_error(y_val, y_proba))   # on probabilities\n",
    "    rmse_label = np.sqrt(mean_squared_error(y_val, y_pred))    # on 0/1 predictions\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} @ threshold={threshold:.2f} ===\")\n",
    "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"RMSE (prob):  {rmse_prob:.4f}\")\n",
    "    print(f\"RMSE (label): {rmse_label:.4f}\")\n",
    "    print(\"Confusion matrix [TN FP; FN TP]:\\n\", cm)\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Threshold\": threshold,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "        \"RMSE_prob\": rmse_prob,\n",
    "        \"RMSE_label\": rmse_label\n",
    "    }\n",
    "\n",
    "# Choose a threshold that maximizes F1 on the val set\n",
    "def best_f1_threshold(pipeline, grid=np.linspace(0.1, 0.9, 17)):\n",
    "    model = clone(pipeline).fit(X_tr, y_tr)\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    best_th, best_f1 = 0.5, -1.0\n",
    "    for th in grid:\n",
    "        f1 = f1_score(y_val, (y_proba >= th).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_th = f1, th\n",
    "    return best_th, best_f1\n",
    "\n",
    "# Find per-model best thresholds (fast) and evaluate at both 0.5 and best-F1\n",
    "results = []\n",
    "\n",
    "# Logistic (L1)\n",
    "th_logit, f1_logit = best_f1_threshold(best_logit)\n",
    "results.append(evaluate_pipeline(best_logit, \"Logistic L1\", threshold=0.5))\n",
    "results.append(evaluate_pipeline(best_logit, \"Logistic L1 (best-F1 th)\", threshold=th_logit))\n",
    "\n",
    "# Decision Tree\n",
    "th_tree, f1_tree = best_f1_threshold(best_tree)\n",
    "results.append(evaluate_pipeline(best_tree, \"Decision Tree (depth≈5)\", threshold=0.5))\n",
    "results.append(evaluate_pipeline(best_tree, \"Decision Tree (best-F1 th)\", threshold=th_tree))\n",
    "\n",
    "# Compact comparison table\n",
    "eval_df = pd.DataFrame(results)\n",
    "eval_df = eval_df[[\"Model\", \"Threshold\", \"Precision\", \"F1\", \"RMSE_prob\", \"RMSE_label\"]]\n",
    "eval_df.sort_values(by=[\"F1\", \"Precision\"], ascending=False, inplace=True)\n",
    "eval_df.reset_index(drop=True, inplace=True)\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb734ab-f549-4994-b3cd-2be413041403",
   "metadata": {},
   "source": [
    "## Based on the Module 20 lesson on Voting Classifier, I am tyring to determine if adding a Voting Classifier will help improve the F1 and precision scores. I investigated both Hard and Soft voting. ## I re-ran the above Voting Classifier code with weight ratio of 3:1 for Decision_Tree:Logistic Regression. This is because, in the original model, Decision Tree performed better than Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f13412d1-99a1-4d54-b725-d3230a3970d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VotingClassifier (HARD) — Logistic L1 + Decision Tree ===\n",
      "AUC: 0.6680 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19869     0]\n",
      " [  113     0]]\n",
      "\n",
      "=== VotingClassifier (SOFT @ threshold=0.50) — Logistic L1 + Decision Tree ===\n",
      "AUC: 0.6680 | Precision: 0.0293 | Recall: 0.2743 | F1: 0.0530\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[18843  1026]\n",
      " [   82    31]]\n",
      "\n",
      "=== VotingClassifier (SOFT @ best-F1 threshold=0.70) — Logistic L1 + Decision Tree ===\n",
      "AUC: 0.6680 | Precision: 0.1176 | Recall: 0.2301 | F1: 0.1557\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19674   195]\n",
      " [   87    26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Option A: HARD voting\n",
    "hard_voter = VotingClassifier(\n",
    "    estimators=[('logit', best_logit), ('tree', best_tree)],\n",
    "    voting='hard',\n",
    "    n_jobs=1\n",
    ")\n",
    "hard_voter.fit(X_tr, y_tr)\n",
    "y_pred_hard = hard_voter.predict(X_val)\n",
    "\n",
    "# Manually build a probability score for AUC (since voting='hard' has no predict_proba)\n",
    "probas = []\n",
    "for name, est in hard_voter.named_estimators_.items():\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        probas.append(est.predict_proba(X_val)[:, 1])\n",
    "    elif hasattr(est, \"decision_function\"):\n",
    "        df = est.decision_function(X_val)\n",
    "        # Min-max to [0,1] so roc_auc_score can use it\n",
    "        s = (df - df.min()) / (df.max() - df.min() + 1e-12)\n",
    "        probas.append(s)\n",
    "# Average scores across members (unweighted, consistent with hard voting)\n",
    "y_score_hard = np.mean(probas, axis=0) if len(probas) > 0 else y_pred_hard.astype(float)\n",
    "auc_hard = roc_auc_score(y_val, y_score_hard)\n",
    "\n",
    "print(\"\\n=== VotingClassifier (HARD) — Logistic L1 + Decision Tree ===\")\n",
    "print(f\"AUC: {auc_hard:.4f} | \"\n",
    "      f\"Precision: {precision_score(y_val, y_pred_hard, zero_division=0):.4f} | \"\n",
    "      f\"Recall: {recall_score(y_val, y_pred_hard, zero_division=0):.4f} | \"\n",
    "      f\"F1: {f1_score(y_val, y_pred_hard, zero_division=0):.4f}\")\n",
    "print(\"Confusion matrix [TN FP; FN TP]:\\n\", confusion_matrix(y_val, y_pred_hard))\n",
    "\n",
    "\n",
    "# Option B: SOFT voting\n",
    "soft_voter = VotingClassifier(\n",
    "    estimators=[('logit', best_logit), ('tree', best_tree)],\n",
    "    voting='soft',\n",
    "    weights=[1, 3],\n",
    "    n_jobs=1\n",
    ")\n",
    "soft_voter.fit(X_tr, y_tr)\n",
    "\n",
    "y_proba_soft = soft_voter.predict_proba(X_val)[:, 1]\n",
    "y_pred_soft_05 = (y_proba_soft >= 0.5).astype(int)\n",
    "auc_soft = roc_auc_score(y_val, y_proba_soft)\n",
    "\n",
    "print(\"\\n=== VotingClassifier (SOFT @ threshold=0.50) — Logistic L1 + Decision Tree ===\")\n",
    "print(f\"AUC: {auc_soft:.4f} | \"\n",
    "      f\"Precision: {precision_score(y_val, y_pred_soft_05, zero_division=0):.4f} | \"\n",
    "      f\"Recall: {recall_score(y_val, y_pred_soft_05, zero_division=0):.4f} | \"\n",
    "      f\"F1: {f1_score(y_val, y_pred_soft_05, zero_division=0):.4f}\")\n",
    "print(\"Confusion matrix [TN FP; FN TP]:\\n\", confusion_matrix(y_val, y_pred_soft_05))\n",
    "\n",
    "\n",
    "# Option C: SOFT voting @ best-F1 threshold\n",
    "def best_f1_threshold_for(ensemble, X_val, y_val, grid=np.linspace(0.05, 0.95, 19)):\n",
    "    proba = ensemble.predict_proba(X_val)[:, 1]\n",
    "    best_th, best_f1 = 0.5, -1.0\n",
    "    for th in grid:\n",
    "        f1 = f1_score(y_val, (proba >= th).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_th, best_f1 = th, f1\n",
    "    return best_th, best_f1\n",
    "\n",
    "best_th, best_f1 = best_f1_threshold_for(soft_voter, X_val, y_val)\n",
    "y_pred_soft_best = (y_proba_soft >= best_th).astype(int)\n",
    "# AUC is threshold-free; reuse y_proba_soft\n",
    "auc_soft_best = roc_auc_score(y_val, y_proba_soft)\n",
    "\n",
    "print(f\"\\n=== VotingClassifier (SOFT @ best-F1 threshold={best_th:.2f}) — Logistic L1 + Decision Tree ===\")\n",
    "print(f\"AUC: {auc_soft_best:.4f} | \"\n",
    "      f\"Precision: {precision_score(y_val, y_pred_soft_best, zero_division=0):.4f} | \"\n",
    "      f\"Recall: {recall_score(y_val, y_pred_soft_best, zero_division=0):.4f} | \"\n",
    "      f\"F1: {f1_score(y_val, y_pred_soft_best, zero_division=0):.4f}\")\n",
    "print(\"Confusion matrix [TN FP; FN TP]:\\n\", confusion_matrix(y_val, y_pred_soft_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719448be-1490-44ce-b665-f7497dca6420",
   "metadata": {},
   "source": [
    "## Original run: Results from VotingClassifier with balanced weights: \n",
    "## === VotingClassifier (HARD) — Logistic L1 + Decision Tree ===\n",
    "Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
    "Confusion matrix [TN FP; FN TP]:\n",
    " [[19870     0]\n",
    " [  112     0]]\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00     19870\n",
    "           1       0.00      0.00      0.00       112\n",
    "\n",
    "    accuracy                           0.99     19982\n",
    "   macro avg       0.50      0.50      0.50     19982\n",
    "weighted avg       0.99      0.99      0.99     19982\n",
    "\n",
    "\n",
    "=== VotingClassifier (SOFT, th=0.50) — Logistic L1 + Decision Tree ===\n",
    "Precision: 0.5000 | Recall: 0.0089 | F1: 0.0175\n",
    "Confusion matrix [TN FP; FN TP]:\n",
    " [[19869     1]\n",
    " [  111     1]]\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00     19870\n",
    "           1       0.50      0.01      0.02       112\n",
    "\n",
    "    accuracy                           0.99     19982\n",
    "   macro avg       0.75      0.50      0.51     19982\n",
    "weighted avg       0.99      0.99      0.99     19982\n",
    "\n",
    "\n",
    "Best-F1 threshold for SOFT voter: 0.45 | F1: 0.1232\n",
    "Confusion matrix [TN FP; FN TP]:\n",
    " [[19723   147]\n",
    " [   95    17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8f2f2-fae4-4da4-95a8-02c3b3321585",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabec8f-41cd-48a5-b36f-337e1c139cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd3a763-7d0a-4cfc-bce0-2a1023513b61",
   "metadata": {},
   "source": [
    "## Now, I will use XGBoost to see if the performance is better. It uses a preprocessing path for trees (no scaling), compresses high-cardinality OHE with SVD, tunes a small hyperparam space with HalvingRandomSearchCV, and then evaluates with both 0.5 and best-F1 thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e561f26a-680e-4fef-b8c9-b76dfe4d9cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\mithr\\anaconda3\\lib\\site-packages (3.0.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\mithr\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mithr\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76f6faf3-4076-4303-82fb-521467bdf113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight ~ 164.7  (neg=99321, pos=603)\n",
      "\n",
      "=== Halving search (XGB) on 30k subset ===\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 8000\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 3\n",
      "n_resources: 8000\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 2\n",
      "n_resources: 16000\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best AUC (tune): 0.5998508361529263\n",
      "Best params: {'clf__subsample': 0.7, 'clf__reg_lambda': 1.0, 'clf__n_estimators': 800, 'clf__max_depth': 4, 'clf__learning_rate': 0.1, 'clf__colsample_bytree': 0.7}\n",
      "\n",
      "=== XGBoost @ threshold=0.50 ===\n",
      "AUC: 0.5753 | Precision: 0.2667 | Recall: 0.0331 | F1: 0.0588\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19853    11]\n",
      " [  117     4]]\n",
      "\n",
      "=== XGBoost @ best-F1 threshold=0.60 ===\n",
      "AUC: 0.5753 | Precision: 0.3333 | Recall: 0.0331 | F1: 0.0602\n",
      "Confusion matrix [TN FP; FN TP]:\n",
      " [[19856     8]\n",
      " [  117     4]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Class imbalance weight (helps XGBoost)\n",
    "pos = int(y.sum())\n",
    "neg = int(len(y) - pos)\n",
    "scale_pos_weight = (neg / max(pos, 1))\n",
    "print(f\"scale_pos_weight ~ {scale_pos_weight:.1f}  (neg={neg}, pos={pos})\")\n",
    "\n",
    "# Preprocessor for XGB (tree-friendly): median impute for num; OHE to SVD for categorical\n",
    "def make_ohe_slim():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=10, sparse_output=True)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown='ignore', max_categories=50, sparse=True)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "\n",
    "preproc_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numeric_features),\n",
    "        ('cat_svd', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     make_ohe_slim()),\n",
    "            ('svd',     TruncatedSVD(n_components=100, n_iter=2, random_state=42))\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "# XGB pipeline \n",
    "xgb_base = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    tree_method='hist',\n",
    "    eval_metric='auc',\n",
    "    n_estimators=400,          # will be tuned\n",
    "    learning_rate=0.1,         # will be tuned\n",
    "    max_depth=6,               # will be tuned\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=1                   \n",
    ")\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "    ('prep', preproc_xgb),\n",
    "    ('clf',  xgb_base),\n",
    "])\n",
    "\n",
    "# Light-weight hyperparam search on the 30k tune subset\n",
    "cv3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'clf__n_estimators': [300, 500, 800],\n",
    "    'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'clf__max_depth': [4, 6, 8],\n",
    "    'clf__subsample': [0.7, 0.85, 1.0],\n",
    "    'clf__colsample_bytree': [0.7, 0.9, 1.0],\n",
    "    'clf__reg_lambda': [0.5, 1.0, 2.0],\n",
    "}\n",
    "\n",
    "print(\"\\n=== Halving search (XGB) on 30k subset ===\")\n",
    "xgb_search = HalvingRandomSearchCV(\n",
    "    estimator=xgb_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    factor=2,\n",
    "    min_resources=8000,        \n",
    "    resource='n_samples',\n",
    "    cv=cv3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_tune, y_tune)\n",
    "print(\"Best AUC (tune):\", xgb_search.best_score_)\n",
    "print(\"Best params:\", xgb_search.best_params_)\n",
    "\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# Evaluate the X_val, y_val\n",
    "# Fixed 0.5 threshold\n",
    "y_proba = best_xgb.predict_proba(X_val)[:, 1]\n",
    "y_pred_05 = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "auc  = roc_auc_score(y_val, y_proba)\n",
    "prec = precision_score(y_val, y_pred_05, zero_division=0)\n",
    "rec  = recall_score(y_val, y_pred_05, zero_division=0)\n",
    "f1   = f1_score(y_val, y_pred_05, zero_division=0)\n",
    "\n",
    "print(\"\\n=== XGBoost @ threshold=0.50 ===\")\n",
    "print(f\"AUC: {auc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "print(\"Confusion matrix [TN FP; FN TP]:\\n\", confusion_matrix(y_val, y_pred_05))\n",
    "\n",
    "# Best-F1 threshold (often better on imbalanced data)\n",
    "ths = np.linspace(0.05, 0.95, 19)\n",
    "best_th, best_f1 = 0.5, -1.0\n",
    "for t in ths:\n",
    "    f1t = f1_score(y_val, (y_proba >= t).astype(int), zero_division=0)\n",
    "    if f1t > best_f1:\n",
    "        best_f1, best_th = f1t, t\n",
    "\n",
    "y_pred_best = (y_proba >= best_th).astype(int)\n",
    "prec_b = precision_score(y_val, y_pred_best, zero_division=0)\n",
    "rec_b  = recall_score(y_val, y_pred_best, zero_division=0)\n",
    "\n",
    "print(f\"\\n=== XGBoost @ best-F1 threshold={best_th:.2f} ===\")\n",
    "print(f\"AUC: {auc:.4f} | Precision: {prec_b:.4f} | Recall: {rec_b:.4f} | F1: {best_f1:.4f}\")\n",
    "print(\"Confusion matrix [TN FP; FN TP]:\\n\", confusion_matrix(y_val, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a490dd-a11b-43c8-b278-ef4ca0340712",
   "metadata": {},
   "source": [
    "## I will now investigate RandomForest to compare with the results from XGBoost. I trimmed search space, uses HalvingRandomSearchCV, lowers SVD size, increases category bucketing, and parallelizes trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c59d6400-4590-494a-b520-c883ac95f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FAST RF halving search on ~15k subset ===\n",
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 6000\n",
      "max_resources_: 15000\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 2\n",
      "n_resources: 6000\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 1\n",
      "n_resources: 12000\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best AUC-PR (tune): 0.012124136998109984\n",
      "Best params: {'prep__cat__svd__n_components': 80, 'clf__n_estimators': 300, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 0.3, 'clf__max_depth': 12}\n",
      "\n",
      "=== FAST RF @ threshold=0.50 ===\n",
      "AUC-ROC: 0.5837 | AUC-PR: 0.0116 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "CM [TN FP; FN TP]:\n",
      " [[19861     3]\n",
      " [  121     0]]\n",
      "\n",
      "=== FAST RF @ threshold=0.24 ===\n",
      "AUC-ROC: 0.5837 | AUC-PR: 0.0116 | Precision: 0.0274 | Recall: 0.0744 | F1: 0.0401\n",
      "CM [TN FP; FN TP]:\n",
      " [[19545   319]\n",
      " [  112     9]]\n"
     ]
    }
   ],
   "source": [
    " # Random Forest\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Shrink the tuning subset further (e.g., 15k) to speed up\n",
    "sss_fast = StratifiedShuffleSplit(n_splits=1, train_size=min(15000, len(X_tune)), random_state=42)\n",
    "idx_fast, _ = next(sss_fast.split(X_tune, y_tune))\n",
    "X_tune_fast = X_tune.iloc[idx_fast]\n",
    "y_tune_fast = y_tune.iloc[idx_fast]\n",
    "\n",
    "def make_ohe_fast():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=30, sparse_output=True)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown='ignore', max_categories=30, sparse=True)\n",
    "        except TypeError:\n",
    "            return OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "\n",
    "preproc_fast = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='<<MISSING>>')),\n",
    "            ('ohe',     make_ohe_fast()),\n",
    "            ('svd',     TruncatedSVD(n_components=100, n_iter=1, random_state=42))\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "\n",
    "rf_fast = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=16,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_pipe_fast = Pipeline([\n",
    "    ('prep', preproc_fast),\n",
    "    ('clf',  rf_fast),\n",
    "])\n",
    "\n",
    "# Trimmed param space (small, fast)\n",
    "param_dist_fast = {\n",
    "    'prep__cat__svd__n_components': [80, 100, 140],\n",
    "    'clf__n_estimators'           : [200, 300, 400],\n",
    "    'clf__max_depth'              : [12, 16, 20],\n",
    "    'clf__min_samples_leaf'       : [1, 2, 5],\n",
    "    'clf__min_samples_split'      : [2, 5, 10],\n",
    "    'clf__max_features'           : ['sqrt', 0.3, 0.5],\n",
    "}\n",
    "\n",
    "cv2 = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)  # 2-fold speeds things up\n",
    "\n",
    "rf_halving = HalvingRandomSearchCV(\n",
    "    estimator=rf_pipe_fast,\n",
    "    param_distributions=param_dist_fast,\n",
    "    factor=2,\n",
    "    min_resources=6000,                # start smaller\n",
    "    resource='n_samples',\n",
    "    cv=cv2,\n",
    "    scoring='average_precision',       # AUC-PR\n",
    "    n_jobs=1,                          # avoid nested parallelism\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"=== FAST RF halving search on ~15k subset ===\")\n",
    "rf_halving.fit(X_tune_fast, y_tune_fast)\n",
    "best_rf_fast = rf_halving.best_estimator_\n",
    "print(\"Best AUC-PR (tune):\", rf_halving.best_score_)\n",
    "print(\"Best params:\", rf_halving.best_params_)\n",
    "\n",
    "# Evaluate on hold-out\n",
    "proba = best_rf_fast.predict_proba(X_val)[:, 1]\n",
    "pred05 = (proba >= 0.50).astype(int)\n",
    "\n",
    "aucroc = roc_auc_score(y_val, proba)\n",
    "aupr  = average_precision_score(y_val, proba)\n",
    "p05 = precision_score(y_val, pred05, zero_division=0)\n",
    "r05 = recall_score(y_val, pred05, zero_division=0)\n",
    "f05 = f1_score(y_val, pred05, zero_division=0)\n",
    "\n",
    "print(\"\\n=== FAST RF @ threshold=0.50 ===\")\n",
    "print(f\"AUC-ROC: {aucroc:.4f} | AUC-PR: {aupr:.4f} | Precision: {p05:.4f} | Recall: {r05:.4f} | F1: {f05:.4f}\")\n",
    "print(\"CM [TN FP; FN TP]:\\n\", confusion_matrix(y_val, pred05))\n",
    "\n",
    "# Best-F1 threshold (restricted low range for imbalance)\n",
    "ths = np.linspace(0.02, 0.30, 15)\n",
    "best_th = max(ths, key=lambda t: f1_score(y_val, (proba >= t).astype(int), zero_division=0))\n",
    "predB = (proba >= best_th).astype(int)\n",
    "\n",
    "# FIX: use predB (not y_pred_best)\n",
    "pB = precision_score(y_val, predB, zero_division=0)\n",
    "rB = recall_score(y_val, predB, zero_division=0)\n",
    "fB = f1_score(y_val, predB, zero_division=0)\n",
    "cmB = confusion_matrix(y_val, predB)\n",
    "\n",
    "print(f\"\\n=== FAST RF @ threshold={best_th:.2f} ===\")\n",
    "print(f\"AUC-ROC: {aucroc:.4f} | AUC-PR: {aupr:.4f} | Precision: {pB:.4f} | Recall: {rB:.4f} | F1: {fB:.4f}\")\n",
    "print(\"CM [TN FP; FN TP]:\\n\", cmB)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
